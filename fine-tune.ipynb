{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import SiglipImageProcessor, AutoProcessor, SiglipVisionModel\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import shutil\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import pandas as pd\n",
    "\n",
    "class custom_ProjectionHead(nn.Module):\n",
    "    def __init__(self, embedding_dim, projection_dim, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.projection = nn.Linear(embedding_dim, projection_dim)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.fc = nn.Linear(projection_dim, projection_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(projection_dim, eps=1e-6)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        projected = self.projection(x)\n",
    "        x = self.gelu(projected)\n",
    "        x = self.fc(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + projected\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "\n",
    "class MLP_ProjectionHead(nn.Module):\n",
    "    def __init__(self, embedding_dim, projection_dim, hidden_dim=256):\n",
    "        super(MLP_ProjectionHead, self).__init__()\n",
    "        \n",
    "        if hidden_dim:\n",
    "            self.projection = nn.Sequential(\n",
    "                nn.Linear(embedding_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, projection_dim)\n",
    "            )\n",
    "        else:\n",
    "            self.projection = nn.Linear(embedding_dim, projection_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.projection(x)\n",
    "    \n",
    "class BasicDataset(Dataset):\n",
    "    def __init__(self, images_folder, transform=None):\n",
    "        self.images_folder = images_folder\n",
    "        self.transform = transform if transform is not None else transforms.Compose([transforms.ToTensor()])\n",
    "        self.image_paths, self.labels = self._load_images_and_labels()\n",
    "\n",
    "    def _load_images_and_labels(self):\n",
    "        image_paths = []\n",
    "        labels = []\n",
    "\n",
    "        for scene in os.listdir(self.images_folder):\n",
    "            scene_path = os.path.join(self.images_folder, scene)\n",
    "            if os.path.isdir(scene_path):\n",
    "                for obj in os.listdir(scene_path):\n",
    "                    obj_path = os.path.join(scene_path, obj)\n",
    "                    if os.path.isdir(obj_path):\n",
    "                        label = f\"{scene}_{obj}\"\n",
    "                        for img_file in os.listdir(obj_path):\n",
    "                            if img_file.endswith('.jpg'):\n",
    "                                image_paths.append(os.path.join(obj_path, img_file))\n",
    "                                labels.append(label)\n",
    "        return image_paths, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "class TripletDataset(BasicDataset):\n",
    "    def __init__(self, images_folder, transform=None):\n",
    "        super(TripletDataset, self).__init__(images_folder, transform)\n",
    "        self.label_to_indices = {}\n",
    "        for idx, label in enumerate(self.labels):\n",
    "            if label not in self.label_to_indices:\n",
    "                self.label_to_indices[label] = []\n",
    "            self.label_to_indices[label].append(idx)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor_img_path = self.image_paths[idx]\n",
    "        anchor_label = self.labels[idx]\n",
    "        anchor_img = Image.open(anchor_img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            anchor_img = self.transform(anchor_img)\n",
    "\n",
    "        positive_idx = random.choice(self.label_to_indices[anchor_label])\n",
    "        positive_img_path = self.image_paths[positive_idx]\n",
    "        positive_img = Image.open(positive_img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            positive_img = self.transform(positive_img)\n",
    "\n",
    "        negative_label = random.choice([label for label in self.label_to_indices.keys() if label != anchor_label])\n",
    "        negative_idx = random.choice(self.label_to_indices[negative_label])\n",
    "        negative_img_path = self.image_paths[negative_idx]\n",
    "        negative_img = Image.open(negative_img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            negative_img = self.transform(negative_img)\n",
    "        \n",
    "        return anchor_img, positive_img, negative_img, anchor_label, negative_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.triplet_loss = nn.TripletMarginLoss(margin=margin)\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        return self.triplet_loss(anchor, positive, negative)   \n",
    "\n",
    "def split_dataset(full_dataset_dir, output_dir, val_split=0.2, seed=42, num_images_per_obj=30):\n",
    "    random.seed(seed)\n",
    "    \n",
    "    train_dir = os.path.join(output_dir, 'train')\n",
    "    val_dir = os.path.join(output_dir, 'val')\n",
    "    \n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "    \n",
    "    for scene in os.listdir(full_dataset_dir):\n",
    "        scene_path = os.path.join(full_dataset_dir, scene)\n",
    "        if os.path.isdir(scene_path):\n",
    "            os.makedirs(os.path.join(train_dir, scene), exist_ok=True)\n",
    "            os.makedirs(os.path.join(val_dir, scene), exist_ok=True)\n",
    "            \n",
    "            for obj in os.listdir(scene_path):\n",
    "                obj_path = os.path.join(scene_path, obj)\n",
    "                if os.path.isdir(obj_path):\n",
    "                    train_obj_dir = os.path.join(train_dir, scene, obj)\n",
    "                    val_obj_dir = os.path.join(val_dir, scene, obj)\n",
    "                    \n",
    "                    os.makedirs(train_obj_dir, exist_ok=True)\n",
    "                    os.makedirs(val_obj_dir, exist_ok=True)\n",
    "                    \n",
    "                    img_files = [f for f in os.listdir(obj_path) if f.endswith('.jpg')]\n",
    "                    \n",
    "                    img_files.sort()\n",
    "                    \n",
    "                    if len(img_files) > num_images_per_obj:\n",
    "                        step = len(img_files) // num_images_per_obj\n",
    "                        sampled_files = [img_files[i * step] for i in range(num_images_per_obj)]\n",
    "                    else:\n",
    "                        sampled_files = img_files\n",
    "                    \n",
    "                    random.shuffle(sampled_files)\n",
    "                    \n",
    "                    split_idx = int(len(sampled_files) * (1 - val_split))\n",
    "                    train_files = sampled_files[:split_idx]\n",
    "                    val_files = sampled_files[split_idx:]\n",
    "\n",
    "                    for file in train_files:\n",
    "                        shutil.copy(os.path.join(obj_path, file), train_obj_dir)\n",
    "                    \n",
    "                    for file in val_files:\n",
    "                        shutil.copy(os.path.join(obj_path, file), val_obj_dir)\n",
    "    \n",
    "    print(f\"Dataset split complete. Training data in: {train_dir}, Validation data in: {val_dir}\")\n",
    "\n",
    "def validate(model, processor, projection_head, dataloader, criterion, device):\n",
    "    projection_head.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for anchor_imgs, positive_imgs, negative_imgs, _, _ in dataloader:\n",
    "\n",
    "            anchor_imgs = (anchor_imgs * 255).byte()\n",
    "            positive_imgs = (positive_imgs * 255).byte()\n",
    "            negative_imgs = (negative_imgs * 255).byte()\n",
    "\n",
    "            anchor_imgs = anchor_imgs.to(device)\n",
    "            positive_imgs = positive_imgs.to(device)\n",
    "            negative_imgs = negative_imgs.to(device)\n",
    "            \n",
    "            anchor_inputs = processor(images=anchor_imgs, return_tensors=\"pt\").to(device)\n",
    "            positive_inputs = processor(images=positive_imgs, return_tensors=\"pt\").to(device)\n",
    "            negative_inputs = processor(images=negative_imgs, return_tensors=\"pt\").to(device)\n",
    "            \n",
    "            anchor_outputs = model(**anchor_inputs)\n",
    "            positive_outputs = model(**positive_inputs)\n",
    "            negative_outputs = model(**negative_inputs)\n",
    "            \n",
    "            anchor_embeddings = projection_head(anchor_outputs.pooler_output)\n",
    "            positive_embeddings = projection_head(positive_outputs.pooler_output)\n",
    "            negative_embeddings = projection_head(negative_outputs.pooler_output)\n",
    "            \n",
    "            loss = criterion(anchor_embeddings, positive_embeddings, negative_embeddings)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss\n",
    "\n",
    "def plot_initial_embeddings(model, processor, projection_head, dataloader, device, output_dir, label_to_idx):\n",
    "    projection_head.eval()\n",
    "    initial_embeddings = []\n",
    "    initial_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for anchor_imgs, _, _, anchor_labels, _ in dataloader:\n",
    "            anchor_imgs = (anchor_imgs * 255).byte()\n",
    "            anchor_imgs = anchor_imgs.to(device)\n",
    "            anchor_inputs = processor(images=anchor_imgs, return_tensors=\"pt\").to(device)\n",
    "            anchor_outputs = model(**anchor_inputs)\n",
    "            anchor_embeddings = projection_head(anchor_outputs.pooler_output)\n",
    "            \n",
    "            initial_embeddings.append(anchor_embeddings)\n",
    "\n",
    "            for label in anchor_labels:\n",
    "                initial_labels.append(label_to_idx[label])\n",
    "\n",
    "            # initial_labels.extend(label_to_idx[anchor_labels])\n",
    "\n",
    "    initial_embeddings = torch.cat(initial_embeddings)\n",
    "    initial_labels = torch.tensor(initial_labels)\n",
    "    \n",
    "    plot_embeddings(initial_embeddings, initial_labels, 0, output_dir)\n",
    "\n",
    "def plot_embeddings(embeddings, labels, epoch, output_dir):\n",
    "    pca2 = PCA(n_components=2)\n",
    "    pca2_result = pca2.fit_transform(embeddings.cpu().detach().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(pca2_result[:, 0], pca2_result[:, 1], c=labels.cpu().numpy(), cmap='tab10', alpha=0.6)\n",
    "    plt.title(f\"PCA of Embeddings at Epoch {epoch}\")\n",
    "    plt.xlabel(\"PCA Component 1\")\n",
    "    plt.ylabel(\"PCA Component 2\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    pca2_dir = os.path.join(output_dir, \"PCA_2\")\n",
    "    os.makedirs(pca2_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(pca2_dir, f\"epoch_{epoch}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    pca3 = PCA(n_components=3)\n",
    "    pca3_result = pca3.fit_transform(embeddings.cpu().detach().numpy())\n",
    "    color_sequence = px.colors.qualitative.Set1\n",
    "    labels_df = pd.DataFrame({'label': labels.cpu().numpy()})\n",
    "\n",
    "    fig = px.scatter_3d(\n",
    "        x=pca3_result[:, 0],\n",
    "        y=pca3_result[:, 1],\n",
    "        z=pca3_result[:, 2],\n",
    "        color=labels_df['label'].astype(str), \n",
    "        title=f\"PCA of Embeddings at Epoch {epoch}\",\n",
    "        labels={\"x\": \"PCA Component 1\", \"y\": \"PCA Component 2\", \"z\": \"PCA Component 3\"},\n",
    "        color_discrete_sequence=color_sequence\n",
    "    )\n",
    "\n",
    "    fig.update_layout(legend_title_text='Labels')\n",
    "\n",
    "    pca3_dir = os.path.join(output_dir, \"PCA_3\")\n",
    "    os.makedirs(pca3_dir, exist_ok=True)\n",
    "    pio.write_html(fig, file=os.path.join(pca3_dir, f\"epoch_{epoch}_3d.html\"))\n",
    "    fig.write_image(os.path.join(pca3_dir, f\"epoch_{epoch}_3d.png\"))\n",
    "\n",
    "def train(model, processor, projection_head, train_loader, val_loader, optimizer, scheduler, criterion, label_to_idx, device, plots_dir, num_epochs=10):\n",
    "\n",
    "    plot_initial_embeddings(model, processor, projection_head, train_loader, device, plots_dir, label_to_idx)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        projection_head.train()\n",
    "        total_loss = 0\n",
    "        epoch_embeddings = []\n",
    "        epoch_labels = []\n",
    "\n",
    "        for anchor_imgs, positive_imgs, negative_imgs, anchor_labels, _ in train_loader:\n",
    "\n",
    "            anchor_imgs = (anchor_imgs * 255).byte()\n",
    "            positive_imgs = (positive_imgs * 255).byte()\n",
    "            negative_imgs = (negative_imgs * 255).byte()\n",
    "\n",
    "            anchor_imgs = anchor_imgs.to(device)\n",
    "            positive_imgs = positive_imgs.to(device)\n",
    "            negative_imgs = negative_imgs.to(device)\n",
    "            \n",
    "            anchor_inputs = processor(images=list(anchor_imgs), return_tensors=\"pt\").to(device)\n",
    "            positive_inputs = processor(images=list(positive_imgs), return_tensors=\"pt\").to(device)\n",
    "            negative_inputs = processor(images=list(negative_imgs), return_tensors=\"pt\").to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                anchor_outputs = model(**anchor_inputs)\n",
    "                positive_outputs = model(**positive_inputs)\n",
    "                negative_outputs = model(**negative_inputs)\n",
    "                \n",
    "            anchor_embeddings = projection_head(anchor_outputs.pooler_output)\n",
    "            positive_embeddings = projection_head(positive_outputs.pooler_output)\n",
    "            negative_embeddings = projection_head(negative_outputs.pooler_output)\n",
    "\n",
    "            loss = criterion(anchor_embeddings, positive_embeddings, negative_embeddings)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            epoch_embeddings.append(anchor_embeddings)\n",
    "            for label in anchor_labels:\n",
    "                epoch_labels.append(label_to_idx[label])\n",
    "        \n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        avg_val_loss = validate(model, processor, projection_head, val_loader, criterion, device)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        logging.info(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        epoch_embeddings = torch.cat(epoch_embeddings)\n",
    "        epoch_labels = torch.tensor(epoch_labels)  # Convert list of indices to tensor\n",
    "        \n",
    "        plot_embeddings(epoch_embeddings, epoch_labels, epoch, plots_dir)\n",
    "\n",
    "    logging.info(\"Training complete.\")\n",
    "\n",
    "def setup_finetuning(data, siglip_version, projection_head, loss, batch_size, lr, num_epochs=10):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    original_dataset = os.path.join(os.getcwd(), \"outputs/masked_images/\", data)\n",
    "    custom_dataset = os.path.join(os.getcwd(), \"custom_dataset/\", data)\n",
    "    if not os.path.isdir(custom_dataset):\n",
    "        os.makedirs(custom_dataset, exist_ok=True)\n",
    "        split_dataset(original_dataset, custom_dataset, val_split=0.2, num_images_per_obj=50)\n",
    "\n",
    "    train_images_folder = os.path.join(custom_dataset, \"train\")\n",
    "    val_images_folder = os.path.join(custom_dataset, \"val\")\n",
    "\n",
    "    if isinstance(loss, TripletLoss):\n",
    "        loss_type = \"triplet_loss\"\n",
    "        train_dataset = TripletDataset(train_images_folder)\n",
    "        val_dataset = TripletDataset(val_images_folder)\n",
    "        idx_to_labels = list(set(train_dataset.labels) | set(val_dataset.labels))\n",
    "        labels_to_idx = {label: idx for idx, label in enumerate(idx_to_labels)}\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    else:\n",
    "        print(\"Unknown loss type\")\n",
    "        return\n",
    "\n",
    "    plots_dir = os.path.join(os.getcwd(), f\"plots/{data}/{loss_type}\")\n",
    "    logs_dir = os.path.join(os.getcwd(), f\"logs/{data}/{loss_type}\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    os.makedirs(logs_dir, exist_ok=True)\n",
    "    log_file = os.path.join(logs_dir, \"training.log\")\n",
    "    logging.basicConfig(filename=log_file, level=logging.INFO, \n",
    "                        format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    siglip_vision_model = SiglipVisionModel.from_pretrained(siglip_version).to(device)\n",
    "    siglip_processor = AutoProcessor.from_pretrained(siglip_version)\n",
    "    projection_head = projection_head.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(projection_head.parameters(), lr=lr)\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "    train(siglip_vision_model, siglip_processor, projection_head, train_loader, val_loader, optimizer, scheduler, loss, labels_to_idx, device, plots_dir, num_epochs=num_epochs)\n",
    "\n",
    "setup_finetuning(\n",
    "    data = \"project_without_occlusion\",\n",
    "    siglip_version=\"google/siglip-base-patch16-224\",\n",
    "    projection_head = custom_ProjectionHead(embedding_dim=768, projection_dim=256),\n",
    "    # projection_head = MLP_ProjectionHead(embedding_dim=768, projection_dim=768, hidden_dim=256),\n",
    "    loss = TripletLoss(1.0),\n",
    "    batch_size=128,\n",
    "    lr=1e-3,\n",
    "    num_epochs=10\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practical-work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
