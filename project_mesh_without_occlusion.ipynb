{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "import cv2\n",
    "\n",
    "import json\n",
    "\n",
    "current_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ScanNet scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan = \"scene0000_00\"\n",
    "\n",
    "scan_path = os.path.join(current_directory, \"data/scans\", scan)\n",
    "scene_mesh_path = os.path.join(scan_path, scan + \"_vh_clean_2.ply\")\n",
    "scene_mesh = o3d.io.read_triangle_mesh(scene_mesh_path)\n",
    "segmentation_mesh_path = os.path.join(scan_path, scan + \"_vh_clean_2.labels.ply\")\n",
    "segmentation_mesh = o3d.io.read_triangle_mesh(segmentation_mesh_path)\n",
    "\n",
    "# o3d.visualization.draw_geometries([scene_mesh])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class must be chosen among one of the raw_category in the [scannetv2-labels.combinesd.tsv](data/scannetv2-labels.combined.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All labels in the aggregation data:  {'toaster oven', 'dish rack', 'couch', 'wall', 'table', 'shower', 'tissue box', 'doorframe', 'refrigerator', 'kitchen cabinets', 'floor', 'tv', 'bed', 'clock', 'backpack', 'mirror', 'sink', 'stool', 'bicycle', 'desk', 'door', 'toaster', 'shoes', 'curtain', 'guitar', 'cabinet', 'nightstand', 'pillow', 'ceiling', 'laundry basket', 'trash can', 'coffee table', 'microwave', 'shelf', 'toilet', 'object', 'kitchen counter', 'guitar case', 'scale', 'window'}\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(scan_path, scan + '_vh_clean.aggregation.json')) as f:\n",
    "    aggregation_data = json.load(f)\n",
    "\n",
    "all_classes = set()\n",
    "for seg_group in aggregation_data['segGroups']:\n",
    "    all_classes.add(seg_group['label'])\n",
    "\n",
    "print(\"All labels in the aggregation data: \", all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 objects for class bed: [37]\n"
     ]
    }
   ],
   "source": [
    "class_name = 'bed'\n",
    "\n",
    "with open(os.path.join(scan_path, scan + '_vh_clean.aggregation.json')) as f:\n",
    "    aggregation_data = json.load(f)\n",
    "\n",
    "object_ids = []\n",
    "for seg_group in aggregation_data['segGroups']:\n",
    "    if seg_group['label'] == class_name:\n",
    "        object_ids.append(seg_group['objectId'])\n",
    "\n",
    "if not object_ids:\n",
    "    print(\"No objects found for class:\", class_name)\n",
    "else:\n",
    "    print(f\"Found {len(object_ids)} objects for class {class_name}: {object_ids}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_id = 37\n",
    "for seg_group in aggregation_data['segGroups']:\n",
    "    if seg_group['objectId'] == object_id:\n",
    "        selected_instance_segments = seg_group['segments']\n",
    "\n",
    "# Load all vertices\n",
    "with open(os.path.join(scan_path, scan + '_vh_clean_2.0.010000.segs.json')) as f:\n",
    "    segmentation_data = json.load(f)\n",
    "\n",
    "# Load instance vertices\n",
    "all_vertices = np.array(segmentation_data['segIndices'])\n",
    "\n",
    "# Get indices of instance vertices\n",
    "instance_vertices_mask = np.isin(all_vertices, selected_instance_segments)\n",
    "instance_vertex_indices = np.where(instance_vertices_mask)[0]\n",
    "\n",
    "# Filter faces of the mesh: included if all its vertices are part of the instance\n",
    "faces = np.asarray(scene_mesh.triangles)\n",
    "face_mask = np.all(np.isin(faces, instance_vertex_indices), axis=1)\n",
    "instance_faces = faces[face_mask] # Triplets of vertex indices forming each triangle (the indices refer to scene vertices - all of them)\n",
    "instance_vertices = np.asarray(scene_mesh.vertices)[instance_vertex_indices] # Coordinates of each vertex\n",
    "vertex_remap = {scene_idx: instance_idx for instance_idx, scene_idx in enumerate(instance_vertex_indices)}\n",
    "instance_faces = np.vectorize(vertex_remap.get)(instance_faces) # Triplets of vertex indices forming each triangle (the indices refer to instance vertices - masked)\n",
    "\n",
    "# Create the mesh for the selected instance\n",
    "instance_mesh = o3d.geometry.TriangleMesh()\n",
    "instance_mesh.vertices = o3d.utility.Vector3dVector(instance_vertices)\n",
    "instance_mesh.triangles = o3d.utility.Vector3iVector(instance_faces)\n",
    "\n",
    "# o3d.visualization.draw_geometries([instance_mesh])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get camera parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export camera parameters\n",
    "**Note:** This step should be performed only at the beginning of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(filename='/Users/lara/Desktop/Making-CLIP-features-multiview-consistent/data/scans/scene0000_00/scene0000_00.sens', output_path='/Users/lara/Desktop/Making-CLIP-features-multiview-consistent/outputs/reader/scene0000_00', export_depth_images=True, export_color_images=True, export_poses=True, export_intrinsics=True)\n",
      "loading /Users/lara/Desktop/Making-CLIP-features-multiview-consistent/data/scans/scene0000_00/scene0000_00.sens...loaded!\n",
      "exporting 5578  depth frames to /Users/lara/Desktop/Making-CLIP-features-multiview-consistent/outputs/reader/scene0000_00/depth\n",
      "exporting 5578 color frames to /Users/lara/Desktop/Making-CLIP-features-multiview-consistent/outputs/reader/scene0000_00/color\n",
      "exporting 5578 camera poses to /Users/lara/Desktop/Making-CLIP-features-multiview-consistent/outputs/reader/scene0000_00/pose\n",
      "exporting camera intrinsics to /Users/lara/Desktop/Making-CLIP-features-multiview-consistent/outputs/reader/scene0000_00/intrinsic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader_directory = os.path.join(current_directory, \"scripts/SensReader\")\n",
    "sens_file = os.path.join(scan_path, scan + \".sens\")\n",
    "output_directory = os.path.join(current_directory, \"outputs/reader/\"+scan)\n",
    "\n",
    "os.system(f\"python {os.path.join(reader_directory, 'reader.py')} --filename {sens_file} --output_path {output_directory} --export_depth_images --export_color_images --export_poses --export_intrinsics --export_depth_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load camera parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = os.path.join(current_directory, \"outputs/reader/\"+scan)\n",
    "pose_directory = os.path.join(output_directory, \"pose\")\n",
    "originals_directory = os.path.join(output_directory, \"color\")\n",
    "depth_directory = os.path.join(output_directory, \"depth\")\n",
    "pose_files = [f for f in os.listdir(pose_directory) if f.endswith('.txt')]\n",
    "frame_indices = [int(f.split('.')[0]) for f in pose_files]\n",
    "intrinsics = np.loadtxt(os.path.join(output_directory, \"intrinsic\", \"intrinsic_color.txt\"))  # Camera intrinsics\n",
    "# extrinsics = np.loadtxt(os.path.join(output_directory, \"intrinsic\", \"extrinsic_color.txt\"))  # Camera estrinsic\n",
    "camera_intrinsics = intrinsics[:3, :3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select frames that contain the specific object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select minimum_vertices in an image\n",
    "Select the percentage of the object you want in the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1772\n"
     ]
    }
   ],
   "source": [
    "percentage = 60\n",
    "\n",
    "total_vertices = instance_vertices.shape[0]\n",
    "minimum_vertices = int(percentage / 100 * total_vertices)\n",
    "\n",
    "total_faces = instance_faces.shape[0]\n",
    "minimum_faces = int(percentage / 100 * total_vertices)\n",
    "\n",
    "print(minimum_vertices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get masked images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select margin of error for depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tolerance on occlusions in meters\n",
    "error = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get masked images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2d_homogeneous(points_3d, intrinsic, extrinsic):\n",
    "    inv_extrinsic = np.linalg.inv(extrinsic)\n",
    "    points_3d_homogeneous = np.hstack([points_3d, np.ones((points_3d.shape[0], 1))])\n",
    "    points_camera = np.dot(inv_extrinsic, points_3d_homogeneous.T).T\n",
    "    points_camera_xyz = points_camera[:, :3] # Extract only the x, y, z components because the intrinsic matrix is 3x3\n",
    "    points_2d_homogeneous = np.dot(intrinsic, points_camera_xyz.T).T # the third value is the depth\n",
    "    return points_2d_homogeneous\n",
    "\n",
    "def draw_triangle(img, vertices, color):\n",
    "    cv2.fillConvexPoly(img, vertices, color)\n",
    "\n",
    "def get_depth_map(frame_index, h, w):\n",
    "    depth_path = os.path.join(depth_directory, f\"{frame_index}.png\")\n",
    "    depth_original = cv2.imread(depth_path, cv2.IMREAD_ANYDEPTH) / 1000\n",
    "    # Depth frames are captured at a resolution of 640 × 480 and color at 1296 × 968 pixels\n",
    "    depth = cv2.resize(depth_original, (h, w))\n",
    "    return depth\n",
    "\n",
    "def get_original_frame(frame_index):\n",
    "    original_path = os.path.join(originals_directory, f\"{frame_index}.jpg\")\n",
    "    return cv2.cvtColor(cv2.imread(original_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def get_camera_extrinsics(frame_index):\n",
    "    extrinsics_path = os.path.join(pose_directory, f\"{frame_index}.txt\")\n",
    "    return  np.loadtxt(extrinsics_path)\n",
    "\n",
    "# Get projected points and z coordinate\n",
    "def get_xyz(vertices, intrinsics, extrinsics):\n",
    "    points_2d = get_2d_homogeneous(vertices, intrinsics, extrinsics)\n",
    "    points_2d_xy = (points_2d[:, :2] / points_2d[:, 2].reshape(-1, 1)).astype(int)\n",
    "    points_2d[:, :2] = points_2d_xy\n",
    "    return points_2d\n",
    "\n",
    "def get_occluded_vertices_idx(depth, points):\n",
    "    total_vertices = points.shape[0]\n",
    "    image_width, image_height = depth.shape\n",
    "    occluded_idx = []\n",
    "    valid_vertices = 0\n",
    "    for vertex in range(total_vertices):\n",
    "        point = points[vertex]\n",
    "        # Check if the vertex falls into the image\n",
    "        if (point[0] >= 0)& (point[0] < image_width) & (point[1] >= 0) & (point[1] < image_height):\n",
    "            # Check if the vertex is in front of the camera\n",
    "            if point[2] > 0:\n",
    "                valid_vertices += 1\n",
    "                # Check if the vertex is occluded\n",
    "                if depth[int(point[0]), int(point[1])] + error < point[2]:\n",
    "                    occluded_idx.append(vertex)\n",
    "    return valid_vertices, occluded_idx\n",
    "\n",
    "def get_camera_for_rendering(camera_extrinsics, camera_intrinsics, h, w):\n",
    "    camera = o3d.camera.PinholeCameraParameters()\n",
    "    intrinsic = o3d.camera.PinholeCameraIntrinsic()\n",
    "    intrinsic.set_intrinsics(width=w, height=h, fx=camera_intrinsics[0][0], fy=camera_intrinsics[1][1], cx=camera_intrinsics[0][2], cy=camera_intrinsics[1][2])\n",
    "    camera.intrinsic = intrinsic\n",
    "    camera.extrinsic = np.array(np.linalg.inv(camera_extrinsics))\n",
    "    return camera\n",
    "\n",
    "def render_image(mesh, camera, w, h):\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window(visible=False, width = w, height = h)\n",
    "    mesh.paint_uniform_color([0, 0, 0])  # Black mesh\n",
    "    vis.add_geometry(mesh)\n",
    "    vis.get_view_control().convert_from_pinhole_camera_parameters(camera, True)\n",
    "    vis.get_render_option().background_color = np.array([1, 1, 1])  # White background\n",
    "    vis.get_render_option().light_on = False\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "    image = vis.capture_screen_float_buffer(do_render=False)\n",
    "    vis.destroy_window()\n",
    "    return image\n",
    "\n",
    "def process_frame(frame_index):\n",
    "    original_frame = get_original_frame(frame_index)\n",
    "    image_height, image_width = original_frame.shape[:2]\n",
    "    camera_extrinsics = get_camera_extrinsics(frame_index)\n",
    "    depth = get_depth_map(frame_index, image_height, image_width)\n",
    "\n",
    "    points_2d = get_xyz(np.asarray(instance_mesh.vertices), camera_intrinsics, camera_extrinsics)\n",
    "\n",
    "    valid_vertices, vertices_to_remove = get_occluded_vertices_idx(depth, points_2d)\n",
    "    \n",
    "    if valid_vertices - len(vertices_to_remove) < minimum_vertices:\n",
    "        return\n",
    "    \n",
    "    vertices_to_remove = set(vertices_to_remove)\n",
    "    all_faces = np.asarray(instance_mesh.triangles)\n",
    "    faces_to_keep = [face for face in all_faces if not any(vertex in vertices_to_remove for vertex in face)]\n",
    "\n",
    "    # Re-index faces: create a mapping from old to new vertex indices\n",
    "    remaining_vertices_indices = list(set(range(len(instance_mesh.vertices))) - vertices_to_remove)\n",
    "    new_index_map = {old_idx: new_idx for new_idx, old_idx in enumerate(remaining_vertices_indices)}\n",
    "    # Update face indices based on new vertex indices\n",
    "    new_faces = [[new_index_map[vertex] for vertex in face] if all(vertex in new_index_map for vertex in face) else None for face in faces_to_keep]\n",
    "    new_faces = [face for face in new_faces if face is not None]\n",
    "    # Get new mesh\n",
    "    new_vertices = np.asarray(instance_mesh.vertices)[remaining_vertices_indices]\n",
    "    new_mesh = o3d.geometry.TriangleMesh()\n",
    "    new_mesh.vertices = o3d.utility.Vector3dVector(new_vertices)\n",
    "    new_mesh.triangles = o3d.utility.Vector3iVector(new_faces)\n",
    "\n",
    "    # Rendering\n",
    "    camera = get_camera_for_rendering(camera_extrinsics, camera_intrinsics, image_height, image_width)\n",
    "    image = render_image(new_mesh, camera, image_width, image_height)\n",
    "    image = np.asarray(image)\n",
    "\n",
    "    # Masking\n",
    "    mask = (image[:, :, 0] == 0)\n",
    "    masked_frame_wrong_colors = np.zeros_like(original_frame)\n",
    "    masked_frame_wrong_colors[mask] = original_frame[mask]\n",
    "    masked_frame = cv2.cvtColor(masked_frame_wrong_colors, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    return masked_frame\n",
    "\n",
    "\n",
    "selected_frames = []\n",
    "masked_images_directory = os.path.join(current_directory, \"outputs/masked_images/project_without_occlusion/\"+scan, f\"{object_id}\")\n",
    "if not os.path.exists(masked_images_directory):\n",
    "    os.makedirs(masked_images_directory)\n",
    "\n",
    "for frame_index in frame_indices:\n",
    "    masked_frame = process_frame(frame_index)\n",
    "    if masked_frame is not None:\n",
    "        output_path = os.path.join(masked_images_directory, f\"{frame_index:05d}.jpg\")\n",
    "        cv2.imwrite(output_path, masked_frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practical-work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
